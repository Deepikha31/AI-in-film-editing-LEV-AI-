# AI in Film Editing â€“ Emotion-Driven Cinematic Montage

This project explores how **rule-based artificial intelligence systems** can be used to support
creative decision-making in film editing. The system focuses on **emotion-aware cinematic montage
generation**, where editing rhythm, pacing, and sequencing are adapted to convey different
psychological states such as anxiety, memory recall, and emotional neutrality.

Rather than relying on data-heavy machine learning models, this project demonstrates a
**deterministic creative AI approach**, in which cinematic rules encode emotional intent.
The goal is to show how AI can function as a **creative collaborator**, assisting filmmakers
and storytellers without replacing human authorship.

---

## Main Evaluation File
- **AI_in_Film_Editing.ipynb**

---

## Project Overview

The Jupyter Notebook presents a complete end-to-end system design, including:

- **Problem Definition & Objective**  
  Identifying the lack of emotion-aware logic in automated video editing tools.

- **Selected Project Track**  
  Creative AI / Media Systems.

- **Data Understanding & Preparation**  
  Use of short video clips as narrative fragments, with emotion treated as a symbolic input
  rather than inferred psychological data.

- **Model / System Design**  
  A rule-based montage architecture where different emotional states map to distinct editing
  strategies (e.g., interruptions, reversals, continuity).

- **Core Implementation**  
  Programmatic sequencing logic that assembles clips according to the selected emotional state.

- **Evaluation & Analysis**  
  Qualitative analysis of how editing patterns communicate emotional tone and narrative intent.

- **Ethical Considerations & Responsible AI**  
  Discussion of creative agency, transparency, and the avoidance of emotion inference or
  psychological profiling.

- **Conclusion & Future Scope**  
  Reflection on limitations and potential extensions, including richer emotional vocabularies
  and adaptive editing systems.

---

## Execution Note

Due to execution constraints in hosted notebook environments, video rendering is simulated using
mock objects. The system logic, sequencing rules, and emotional mappings reflect the original
MoviePy-based implementation developed during prototyping.
